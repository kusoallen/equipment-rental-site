
import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup

# è¨­å®š Streamlit é é¢è³‡è¨Š
st.set_page_config(page_title="è£å‚™ç§Ÿå€Ÿå±•ç¤º", layout="wide")
st.title("ğŸ›¡ï¸ è£å‚™ç§Ÿå€Ÿå±•ç¤ºç³»çµ±")

# Google Sheet CSV åŒ¯å‡ºé€£çµï¼ˆè¨˜å¾—è¨­ç‚ºå…¬é–‹ï¼‰
sheet_url = "https://docs.google.com/spreadsheets/d/1VbqOaRt3lWAEJjg-QdGABBT2XdC6B_2ZuIsqrASGmio/export?format=csv"

@st.cache_data
def load_data():
    return pd.read_csv(sheet_url)

@st.cache_data
def get_drive_image_ids(folder_url):
    """è§£æ Google Drive è³‡æ–™å¤¾ï¼Œå–å¾—æª”æ¡ˆåç¨±èˆ‡ ID çš„å°æ‡‰è¡¨"""
    file_ids = {}
    html = requests.get(folder_url).text
    soup = BeautifulSoup(html, 'html.parser')
    for script in soup.find_all("script"):
        if "window.viewerData" in script.text:
            data_start = script.string.find('{')
            data_text = script.string[data_start:]
            try:
                import json
                viewer_data = json.loads(data_text.split("};")[0] + "}")
                for item in viewer_data["docs"]:
                    title = item.get("title")
                    file_id = item.get("id")
                    if title and file_id:
                        name = title.rsplit(".", 1)[0]  # å»æ‰å‰¯æª”å
                        file_ids[name] = file_id
            except Exception as e:
                print("JSON parsing error:", e)
            break
    return file_ids

# è¼‰å…¥è³‡æ–™èˆ‡åœ–ç‰‡ ID å°æ‡‰
df = load_data()
image_ids = get_drive_image_ids("https://drive.google.com/drive/folders/12z1OG5vykinDStN_H8wGD5izxYBw40mW")

# æœå°‹æ¬„
keyword = st.text_input("ğŸ” æœå°‹è£å‚™åç¨±æˆ–å…§å®¹ç‰©é—œéµå­—").strip()
if keyword:
    df = df[df["åç¨±"].str.contains(keyword, case=False, na=False) | df["å…§å®¹ç‰©"].str.contains(keyword, case=False, na=False)]

# é¡åˆ¥ç¯©é¸
categories = ["å…¨éƒ¨"] + sorted(df["åˆ†é¡"].dropna().unique().tolist())
selected = st.radio("ğŸ“‚ é¡åˆ¥ç¯©é¸ï¼š", categories, horizontal=True)
if selected != "å…¨éƒ¨":
    df = df[df["åˆ†é¡"] == selected]

# é¡¯ç¤ºè£å‚™å¡ç‰‡
cols = st.columns(3)
for i, (_, row) in enumerate(df.iterrows()):
    with cols[i % 3]:
        image_id = image_ids.get(row["åç¨±"], "")
        image_url = f"https://drive.google.com/uc?id={image_id}" if image_id else ""
        
if image_url:
    st.image(image_url, use_container_width=True, caption=row["åç¨±"])
else:
    st.warning(f"â— ç„¡åœ–ç‰‡ï¼š{row['åç¨±']}")

st.markdown(f"#### {row['åç¨±']}")
st.markdown(f"ğŸ“¦ åˆ†é¡ï¼š{row['åˆ†é¡']}")
st.markdown(f"ğŸ’° æ¯æ—¥ç§Ÿé‡‘ï¼š${int(row['æ¯æ—¥ç§Ÿé‡‘']) if pd.notna(row['æ¯æ—¥ç§Ÿé‡‘']) else 'â€”'}")
st.markdown(f"ğŸ’¥ æå£è³ å„Ÿåƒ¹ï¼š${int(row['åŸåƒ¹']) if pd.notna(row['åŸåƒ¹']) else 'â€”'}")
å°ºå¯¸ = row["å°ºå¯¸"] if "å°ºå¯¸" in row and pd.notna(row["å°ºå¯¸"]) else "â€”"
st.markdown(f"ğŸ“ å°ºå¯¸ï¼š{å°ºå¯¸}")
st.markdown(f"ğŸ”¹ å…§å®¹ç‰©ï¼š{row['å…§å®¹ç‰©']}")

        st.markdown(f"#### {row['åç¨±']}")
        st.markdown(f"ğŸ“¦ åˆ†é¡ï¼š{row['åˆ†é¡']}")
        st.markdown(f"ğŸ’° æ¯æ—¥ç§Ÿé‡‘ï¼š${int(row['æ¯æ—¥ç§Ÿé‡‘']) if pd.notna(row['æ¯æ—¥ç§Ÿé‡‘']) else 'â€”'}")
        st.markdown(f"ğŸ’¥ æå£è³ å„Ÿåƒ¹ï¼š${int(row['åŸåƒ¹']) if pd.notna(row['åŸåƒ¹']) else 'â€”'}")
        å°ºå¯¸ = row["å°ºå¯¸"] if "å°ºå¯¸" in row and pd.notna(row["å°ºå¯¸"]) else "â€”"
        st.markdown(f"ğŸ“ å°ºå¯¸ï¼š{å°ºå¯¸}")
        st.markdown(f"ğŸ”¹ å…§å®¹ç‰©ï¼š{row['å…§å®¹ç‰©']}")

# è¡¨å–®æ¨¡çµ„
st.markdown("---")
st.subheader("ğŸ“ æˆ‘è¦é ç´„ç§Ÿå€Ÿ")

with st.form("rental_form"):
    name = st.text_input("ğŸ‘¤ ä½ çš„åå­—")
    item = st.selectbox("ğŸ“¦ æƒ³ç§Ÿå€Ÿçš„è£å‚™", df["åç¨±"].unique())
    days = st.number_input("ğŸ“† ç§Ÿå€Ÿå¤©æ•¸", min_value=1, value=1)
    submit = st.form_submit_button("é€å‡ºé ç´„")

    if submit:
        st.success(f"æ„Ÿè¬ä½ ï¼Œ{name}ï¼ä½ å·²é ç´„ã€{item}ã€‘ï¼Œç§Ÿå€Ÿ {days} å¤©ã€‚å¾ŒçºŒæœƒèˆ‡ä½ è¯ç¹«ï¼")
